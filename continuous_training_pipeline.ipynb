{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "continuous_training_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMp7qvzIyg7XGeVTkWqpixV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silverstar0727/pose-estimation/blob/main/continuous_training_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHHN6ZRT3rl9"
      },
      "source": [
        "# 해당 셀을 실행한 후에 반드시 \"런타임 다시시작\"을 해주세요\n",
        "!pip install -q kfp\n",
        "!pip3 install --user kfp google-cloud-aiplatform matplotlib --upgrade -q\n",
        "# 추가\n",
        "!pip3 install --user google-cloud-aiplatform --upgrade -q\n",
        "!pip3 install --user kfp google-cloud-pipeline-components --upgrade -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFaOAS8639SU"
      },
      "source": [
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "import kfp\n",
        "from kfp import dsl\n",
        "from kfp.v2 import compiler\n",
        "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
        "                        OutputPath, component, ClassificationMetrics, Metrics)\n",
        "from kfp.v2.google.client import AIPlatformClient\n",
        "from kfp.v2.google import experimental\n",
        "from google.cloud import aiplatform\n",
        "from google_cloud_pipeline_components import aiplatform as gcc_aip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pIyhIZa3_Jz"
      },
      "source": [
        "from google.colab import auth as google_auth\n",
        "\n",
        "google_auth.authenticate_user() # 사용할 gcp 계정으로 연결해주세요"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsJCkin74BTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0318d74-183b-4676-8aa6-efbdd267c8a2"
      },
      "source": [
        "PROJECT_ID = 'natural-expanse-319203'\n",
        "REGION = \"us-central1\"\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "BUCKET_NAME = \"gs://mediapipe-pipeline\"\n",
        "\n",
        "USER = \"JeongMin-Do\"\n",
        "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline_root/{USER}\"\n",
        "\n",
        "WORKING_DIR = PIPELINE_ROOT\n",
        "MODEL_DISPLAY_NAME = f\"train_deploy\"\n",
        "print(WORKING_DIR)\n",
        "print(MODEL_DISPLAY_NAME)\n",
        "\n",
        "\n",
        "aiplatform.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        "    staging_bucket=BUCKET_NAME,\n",
        "    #experiment='my-experiment',\n",
        "    #experiment_description='my experiment decsription'\n",
        ")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://mediapipe-pipeline/pipeline_root/JeongMin-Do\n",
            "train_deploy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10gbboRQ4M42"
      },
      "source": [
        "@component(base_image=\"silverstar456/mediapipe:landmarks\")\n",
        "def get_landmarks(result_csv: OutputPath(\"result_csv\")):\n",
        "    import csv\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "    import os\n",
        "    import sys\n",
        "    import tqdm\n",
        "    import pandas as pd\n",
        "\n",
        "    from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
        "    from mediapipe.python.solutions import pose as mp_pose\n",
        "\n",
        "    import wget \n",
        "    import zipfile\n",
        "\n",
        "    # GCS에서 이미지 파일 다운로드 \n",
        "    wget.download(\"https://storage.googleapis.com/mediapipe-pipeline/study.zip\")\n",
        "\n",
        "    # 압축해제\n",
        "    fantasy_zip = zipfile.ZipFile('study.zip')\n",
        "    fantasy_zip.extractall('.')\n",
        "    fantasy_zip.close()\n",
        "\n",
        "    def landmarks(input_frame):\n",
        "        input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Initialize fresh pose tracker and run it.\n",
        "        with mp_pose.Pose(upper_body_only=True) as pose_tracker:\n",
        "            result = pose_tracker.process(image=input_frame)\n",
        "            pose_landmarks = result.pose_landmarks\n",
        "        \n",
        "        # Save landmarks.\n",
        "        if pose_landmarks is not None:\n",
        "            # Check the number of landmarks and take pose landmarks.\n",
        "            assert len(pose_landmarks.landmark) == 25, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
        "            pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
        "\n",
        "            # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
        "            # correct aspect ratio.\n",
        "            frame_height, frame_width = input_frame.shape[:2]\n",
        "            pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
        "\n",
        "            # Write pose sample to CSV.\n",
        "            pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(np.float64).tolist()\n",
        "\n",
        "            return pose_landmarks\n",
        "\n",
        "    images_in_folder = 'study'\n",
        "    csv_out_path = result_csv\n",
        "\n",
        "    with open(csv_out_path, 'w') as csv_out_file:\n",
        "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
        "\n",
        "        # Folder names are used as pose class names.\n",
        "        pose_class_names = sorted([n for n in os.listdir(images_in_folder) if not n.startswith('.')])\n",
        "\n",
        "        for pose_class_name in pose_class_names:\n",
        "            print('Bootstrapping ', pose_class_name, file=sys.stderr)\n",
        "\n",
        "            image_names = sorted([\n",
        "                n for n in os.listdir(os.path.join(images_in_folder, pose_class_name))\n",
        "                if not n.startswith('.')])\n",
        "            for image_name in tqdm.tqdm(image_names, position=0):\n",
        "                # Load image.\n",
        "                input_frame = cv2.imread(os.path.join(images_in_folder, pose_class_name, image_name))\n",
        "                pose_landmarks = landmarks(input_frame)\n",
        "\n",
        "                try:\n",
        "                    csv_out_writer.writerow([image_name, pose_class_name] + pose_landmarks)\n",
        "                except:\n",
        "                    pass       "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0loVE7Wj_gzZ"
      },
      "source": [
        "# silverstar456/mediapipe:knn\n",
        "# us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\n",
        "@component(base_image=\"silverstar456/mediapipe:knn\")\n",
        "def knn_model(result_csv: InputPath(\"result_csv\"), \n",
        "        model_output: OutputPath(\"model\")\n",
        "        ):\n",
        "    import pandas as pd\n",
        "    import os\n",
        "    from google.cloud import storage\n",
        "\n",
        "    import pickle\n",
        "    from joblib import dump, load\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "    data = pd.read_csv(result_csv, header=None)\n",
        "    x_train, y_train = data.iloc[:, 2:], data.iloc[:, 1]\n",
        "\n",
        "    classifier = KNeighborsClassifier(n_neighbors = 3)\n",
        "\n",
        "    classifier.fit(x_train, y_train)\n",
        "\n",
        "    dump(classifier, model_output) \n",
        "\n",
        "    #blob = storage.blob.Blob.from_string(OutputPath, client=storage.Client())\n",
        "    #blob.upload_from_filename('model.joblib')\n",
        "\n",
        "    # clf = load('filename.joblib') "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdjz9KxihzI-"
      },
      "source": [
        "@component(base_image=\"silverstar456/mediapipe:test\")\n",
        "def model_test(result_csv: InputPath(\"result_csv\"), model_output: InputPath(\"model\")):\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "    import os\n",
        "    import sys\n",
        "    import tqdm\n",
        "    import pandas as pd\n",
        "    from joblib import dump, load\n",
        "\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "    from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
        "    from mediapipe.python.solutions import pose as mp_pose\n",
        "\n",
        "    def landmarks(input_frame):\n",
        "        input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Initialize fresh pose tracker and run it.\n",
        "        with mp_pose.Pose(upper_body_only=True) as pose_tracker:\n",
        "            result = pose_tracker.process(image=input_frame)\n",
        "            pose_landmarks = result.pose_landmarks\n",
        "        \n",
        "        # Save landmarks.\n",
        "        if pose_landmarks is not None:\n",
        "            # Check the number of landmarks and take pose landmarks.\n",
        "            assert len(pose_landmarks.landmark) == 25, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
        "            pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
        "\n",
        "            # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
        "            # correct aspect ratio.\n",
        "            frame_height, frame_width = input_frame.shape[:2]\n",
        "            pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
        "\n",
        "            # Write pose sample to CSV.\n",
        "            pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(np.float64).tolist()\n",
        "\n",
        "            return pose_landmarks\n",
        "\n",
        "    classifier = load(model_output) \n",
        "\n",
        "    data = pd.read_csv(result_csv, header=None)\n",
        "    x, y = data.iloc[:, 2:], data.iloc[:, 1]\n",
        "    correct = 0\n",
        "    for i in range(len(data)):\n",
        "        sample = np.array(x.iloc[i, :]).reshape(1, -1)\n",
        "        pred = classifier.predict(sample)\n",
        "        if pred[0] == y[i]:\n",
        "            correct += 1\n",
        "            \n",
        "    print(correct / len(data))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "7Y0J81gpv5Nz",
        "outputId": "2ca704a4-ac2a-4e94-c639-7699ecfb201a"
      },
      "source": [
        "@dsl.pipeline(\n",
        "    name = \"mediapipe-pipeline2\",\n",
        "    description = \"mediapipe\",\n",
        "    pipeline_root=PIPELINE_ROOT\n",
        ")\n",
        "def mediapipe():\n",
        "    landmarks = get_landmarks()\n",
        "    model = knn_model(landmarks.output)\n",
        "    test = model_test(landmarks.output, model.output)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    model_upload_op = aiplatform.Model.upload(\n",
        "        display_name=MODEL_DISPLAY_NAME,\n",
        "        serving_container_image_uri=\"gcr.io/cloud-aiplatform/prediction/tf2-cpu.2-2:latest\")\n",
        "    \n",
        "    model_upload_op.after(model)\"\"\"\n",
        "\n",
        "\n",
        "compiler.Compiler().compile(\n",
        "    pipeline_func = mediapipe, \n",
        "    package_path = \"mediapipe.json\"\n",
        ")\n",
        "\n",
        "api_client = AIPlatformClient(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        ")\n",
        "\n",
        "response = api_client.create_run_from_job_spec(\n",
        "    job_spec_path=\"mediapipe.json\"\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-2e2dfc21b10e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m compiler.Compiler().compile(\n\u001b[1;32m     22\u001b[0m     \u001b[0mpipeline_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mpackage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mediapipe.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, pipeline_func, package_path, pipeline_name, pipeline_parameters, type_check)\u001b[0m\n\u001b[1;32m   1138\u001b[0m           \u001b[0mpipeline_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m           \u001b[0mpipeline_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m           pipeline_parameters_override=pipeline_parameters)\n\u001b[0m\u001b[1;32m   1141\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_job\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py\u001b[0m in \u001b[0;36m_create_pipeline_v2\u001b[0;34m(self, pipeline_func, pipeline_name, pipeline_parameters_override)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mdsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdsl_pipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m       \u001b[0mpipeline_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_exit_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsl_pipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2e2dfc21b10e>\u001b[0m in \u001b[0;36mmediapipe\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'model_test' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b79QUMAR0ARa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A78-pIjR0AOU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLqlJ7bi2zJ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}