{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "continuous_training_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOf9+Xs9HJtWutgv5JTnSgC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silverstar0727/pose-estimation/blob/main/continuous_training_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE3I7Jz5K6Gn"
      },
      "source": [
        "# 라이브러리 설치 및 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHHN6ZRT3rl9"
      },
      "source": [
        "# 해당 셀을 실행한 후에 반드시 \"런타임 다시시작\"을 해주세요\n",
        "!pip install -q kfp\n",
        "!pip3 install --user google-cloud-aiplatform matplotlib --upgrade -q\n",
        "# 추가\n",
        "!pip3 install --user google-cloud-aiplatform --upgrade -q\n",
        "!pip3 install --user google-cloud-pipeline-components --upgrade -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFaOAS8639SU"
      },
      "source": [
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "import kfp\n",
        "from kfp import dsl\n",
        "from kfp.v2 import compiler\n",
        "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
        "                        OutputPath, component, ClassificationMetrics, Metrics)\n",
        "from kfp.v2.google.client import AIPlatformClient\n",
        "from kfp.v2.google import experimental\n",
        "from google.cloud import aiplatform\n",
        "from google_cloud_pipeline_components import aiplatform as gcc_aip"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unaOMDwgK3vZ"
      },
      "source": [
        "# gcp 계정 연결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pIyhIZa3_Jz"
      },
      "source": [
        "from google.colab import auth as google_auth\n",
        "\n",
        "google_auth.authenticate_user() # 사용할 gcp 계정으로 연결해주세요"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb9J-DtjKzVW"
      },
      "source": [
        "# 경로 변수 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsJCkin74BTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "744c7e20-b1c8-4b02-80bc-9115e32c0d39"
      },
      "source": [
        "PIPELINE_SPEC_NAME = \"mediapipe.json\"\n",
        "\n",
        "PROJECT_ID = 'natural-expanse-319203'\n",
        "REGION = \"us-central1\"\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "BUCKET_NAME = \"gs://mediapipe-pipeline\"\n",
        "\n",
        "USER = \"JeongMin-Do\"\n",
        "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline_root/{USER}\"\n",
        "\n",
        "WORKING_DIR = PIPELINE_ROOT\n",
        "MODEL_DISPLAY_NAME = f\"train_deploy\"\n",
        "\n",
        "MODEL_NAME = \"model.joblib\"\n",
        "print(WORKING_DIR)\n",
        "print(MODEL_DISPLAY_NAME)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://mediapipe-pipeline/pipeline_root/JeongMin-Do\n",
            "train_deploy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEwMxms9Ktrw"
      },
      "source": [
        "# mediapipe pose estimation을 이용한 데이터 전처리 컴포넌트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10gbboRQ4M42"
      },
      "source": [
        "@component(base_image=\"silverstar456/mediapipe:landmarks\")\n",
        "def get_landmarks(result_csv: OutputPath(\"result_csv\")):\n",
        "    import csv\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "    import os\n",
        "    import sys\n",
        "    import tqdm\n",
        "    import pandas as pd\n",
        "\n",
        "    from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
        "    from mediapipe.python.solutions import pose as mp_pose\n",
        "\n",
        "    import wget \n",
        "    import zipfile\n",
        "\n",
        "    # GCS에서 이미지 파일 다운로드 \n",
        "    wget.download(\"https://storage.googleapis.com/mediapipe-pipeline/study.zip\")\n",
        "\n",
        "    # 압축해제\n",
        "    fantasy_zip = zipfile.ZipFile('study.zip')\n",
        "    fantasy_zip.extractall('.')\n",
        "    fantasy_zip.close()\n",
        "\n",
        "    def landmarks(input_frame):\n",
        "        input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Initialize fresh pose tracker and run it.\n",
        "        with mp_pose.Pose(upper_body_only=True) as pose_tracker:\n",
        "            result = pose_tracker.process(image=input_frame)\n",
        "            pose_landmarks = result.pose_landmarks\n",
        "        \n",
        "        # Save landmarks.\n",
        "        if pose_landmarks is not None:\n",
        "            # Check the number of landmarks and take pose landmarks.\n",
        "            assert len(pose_landmarks.landmark) == 25, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
        "            pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
        "\n",
        "            # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
        "            # correct aspect ratio.\n",
        "            frame_height, frame_width = input_frame.shape[:2]\n",
        "            pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
        "\n",
        "            # Write pose sample to CSV.\n",
        "            pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(np.float64).tolist()\n",
        "\n",
        "            return pose_landmarks\n",
        "\n",
        "    images_in_folder = 'study'\n",
        "    csv_out_path = result_csv\n",
        "\n",
        "    with open(csv_out_path, 'w') as csv_out_file:\n",
        "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
        "\n",
        "        # Folder names are used as pose class names.\n",
        "        pose_class_names = sorted([n for n in os.listdir(images_in_folder) if not n.startswith('.')])\n",
        "\n",
        "        for pose_class_name in pose_class_names:\n",
        "            print('Bootstrapping ', pose_class_name, file=sys.stderr)\n",
        "\n",
        "            image_names = sorted([\n",
        "                n for n in os.listdir(os.path.join(images_in_folder, pose_class_name))\n",
        "                if not n.startswith('.')])\n",
        "            for image_name in tqdm.tqdm(image_names, position=0):\n",
        "                # Load image.\n",
        "                input_frame = cv2.imread(os.path.join(images_in_folder, pose_class_name, image_name))\n",
        "                pose_landmarks = landmarks(input_frame)\n",
        "\n",
        "                try:\n",
        "                    csv_out_writer.writerow([image_name, pose_class_name] + pose_landmarks)\n",
        "                except:\n",
        "                    pass"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BgyJxcbKqBT"
      },
      "source": [
        "# knn 훈련 컴포넌트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0loVE7Wj_gzZ"
      },
      "source": [
        "# usable docker image\n",
        "## silverstar456/mediapipe:knn\n",
        "## us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\n",
        "@component(base_image=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\")\n",
        "def knn_model(result_csv: InputPath(\"result_csv\"), \n",
        "        model_output: OutputPath(\"model\"),\n",
        "        model_name: str,\n",
        "        model_path: str\n",
        "        ):\n",
        "    import pandas as pd\n",
        "    import os\n",
        "    from google.cloud import storage\n",
        "\n",
        "    import pickle\n",
        "    from joblib import dump, load\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "    data = pd.read_csv(result_csv, header=None)\n",
        "    x_train, y_train = data.iloc[:, 2:], data.iloc[:, 1]\n",
        "\n",
        "    classifier = KNeighborsClassifier(n_neighbors = 3)\n",
        "\n",
        "    classifier.fit(x_train, y_train)\n",
        "\n",
        "    dump(classifier, model_output) \n",
        "\n",
        "    # upload model to gcs bucket\n",
        "    dump(classifier, model_name)\n",
        "\n",
        "    blob = storage.blob.Blob.from_string(model_path, client=storage.Client())\n",
        "    blob.upload_from_filename(model_name)"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMUgyQWJKnR5"
      },
      "source": [
        "# 모델 평가 컴포넌트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdjz9KxihzI-"
      },
      "source": [
        "@component(base_image=\"silverstar456/mediapipe:test\")\n",
        "def model_test(result_csv: InputPath(\"result_csv\"), \n",
        "               model_output: InputPath(\"model\"), \n",
        "               metrics: Output[Metrics]):\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "    import os\n",
        "    import sys\n",
        "    import tqdm\n",
        "    import pandas as pd\n",
        "    from joblib import dump, load\n",
        "\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "    from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
        "    from mediapipe.python.solutions import pose as mp_pose\n",
        "\n",
        "    def landmarks(input_frame):\n",
        "        input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Initialize fresh pose tracker and run it.\n",
        "        with mp_pose.Pose(upper_body_only=True) as pose_tracker:\n",
        "            result = pose_tracker.process(image=input_frame)\n",
        "            pose_landmarks = result.pose_landmarks\n",
        "        \n",
        "        # Save landmarks.\n",
        "        if pose_landmarks is not None:\n",
        "            # Check the number of landmarks and take pose landmarks.\n",
        "            assert len(pose_landmarks.landmark) == 25, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
        "            pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
        "\n",
        "            # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
        "            # correct aspect ratio.\n",
        "            frame_height, frame_width = input_frame.shape[:2]\n",
        "            pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
        "\n",
        "            # Write pose sample to CSV.\n",
        "            pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(np.float64).tolist()\n",
        "\n",
        "            return pose_landmarks\n",
        "\n",
        "    classifier = load(model_output) \n",
        "\n",
        "    data = pd.read_csv(result_csv, header=None)\n",
        "    x, y = data.iloc[:, 2:], data.iloc[:, 1]\n",
        "    correct = 0\n",
        "    for i in range(len(data)):\n",
        "        sample = np.array(x.iloc[i, :]).reshape(1, -1)\n",
        "        pred = classifier.predict(sample)\n",
        "        if pred[0] == y[i]:\n",
        "            correct += 1\n",
        "\n",
        "    result_acc = correct / len(data)\n",
        "    print(result_acc)\n",
        "\n",
        "    metrics.log_metric(\"accuracy\", (result_acc * 100.0))"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UN8lcrAKiLO"
      },
      "source": [
        "# 모델 등록 및 배포 컴포넌트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9noJLZ70TPJ"
      },
      "source": [
        "@component(base_image=\"silverstar456/mediapipe:aiplatform\")\n",
        "def model_upload(accuracy: Input[Metrics], \n",
        "                 project: str,\n",
        "                 region: str,\n",
        "                 display_name: str, \n",
        "                 artifact_uri: str,):\n",
        "    from google.cloud import aiplatform\n",
        "\n",
        "    aiplatform.init(project=project, location=region)\n",
        "\n",
        "    model = aiplatform.Model.upload(\n",
        "        display_name=display_name,\n",
        "        artifact_uri=artifact_uri,\n",
        "        serving_container_image_uri=\"gcr.io/cloud-aiplatform/prediction/tf2-cpu.2-2:latest\")\n",
        "    \n",
        "    endpoint = model.deploy(machine_type=\"n1-standard-4\",\n",
        "                        min_replica_count=1,\n",
        "                        max_replica_count=1,)"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMji38YkNNZG"
      },
      "source": [
        "@component(base_image=\"silverstar456/mediapipe:aiplatform\")\n",
        "def model_deploy(project: str,\n",
        "                 region: str,):\n",
        "    from google.cloud import aiplatform\n",
        "\n",
        "    aiplatform.init(project=project, location=region)\n",
        "    \n",
        "    model = aiplatform.Model(\"gs://mediapipe-pipeline\")\n",
        "\n",
        "    endpoint = model.deploy(machine_type=\"n1-standard-4\",\n",
        "                        min_replica_count=1,\n",
        "                        max_replica_count=1,)"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWqtFwiuKflU"
      },
      "source": [
        "# 파이프라인 구성 후 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "7Y0J81gpv5Nz",
        "outputId": "aaeb9839-0cb4-478f-af99-265fae1bd7e8"
      },
      "source": [
        "@dsl.pipeline(\n",
        "    name = \"mediapipe-pipeline8\",\n",
        "    description = \"mediapipe\",\n",
        "    pipeline_root=PIPELINE_ROOT\n",
        ")\n",
        "def mediapipe():\n",
        "    landmarks = get_landmarks()\n",
        "    model = knn_model(landmarks.output, \n",
        "                      model_name=MODEL_NAME, \n",
        "                      model_path=f\"{BUCKET_NAME}/{MODEL_NAME}\")\n",
        "    test = model_test(landmarks.output, model.output)\n",
        "\n",
        "    upload = model_upload(test.output,\n",
        "                          project=PROJECT_ID,\n",
        "                          region=REGION,\n",
        "                          display_name=\"mediapipe\",\n",
        "                          artifact_uri=BUCKET_NAME)\n",
        "    #deploy = model_deploy(project=PROJECT_ID,\n",
        "    #                      region=REGION,)\n",
        "    \n",
        "\n",
        "compiler.Compiler().compile(\n",
        "    pipeline_func = mediapipe, \n",
        "    package_path = PIPELINE_SPEC_NAME\n",
        ")\n",
        "\n",
        "api_client = AIPlatformClient(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        ")\n",
        "\n",
        "response = api_client.create_run_from_job_spec(\n",
        "    job_spec_path=PIPELINE_SPEC_NAME\n",
        ")"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/google/client/client.py:175: FutureWarning: AIPlatformClient will be deprecated in v1.9. Please use PipelineJob https://googleapis.dev/python/aiplatform/latest/_modules/google/cloud/aiplatform/pipeline_jobs.html in Vertex SDK. Install the SDK using \"pip install google-cloud-aiplatform\"\n",
            "  category=FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/mediapipe-pipeline8-20210809054822?project=natural-expanse-319203\" target=\"_blank\" >here</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QknYfzmHXc-s"
      },
      "source": [
        ""
      ],
      "execution_count": 185,
      "outputs": []
    }
  ]
}